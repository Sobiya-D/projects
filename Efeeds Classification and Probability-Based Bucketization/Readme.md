•	Implemented a dual-model architecture for text classification, processing over 30,000 records daily.
•	Utilized SGD optimization for efficient learning on 150,000 records in a high-dimensional space.
•	Employed NLP techniques such as TF-IDF vectorization and text normalization for model input preprocessing.
•	Applied probability-based bucketization to categorize records dynamically based on predicted confidence levels.
•	Designed a modular, scalable system supporting batch processing, logging, and parameter configuration.
